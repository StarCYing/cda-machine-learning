{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction:\n",
    "In this workshop we show you an example of a workflow in data science from initial data ingestion, cleaning, modeling, and ultimately clustering. In this example we scrape the news feed of of [NIST](www.nist.gov). For those not in the know, NIST is the National Institute of Standards and Technology. It is comprised of multiple research centers which include: \n",
    "* Center for Nanoscale Science and Technology (CNST)\n",
    "* Engineering Laboratory (EL)\n",
    "* Information Technology Laboratory (ITL)\n",
    "* NIST Center for Neutron Research (NCNR)\n",
    "* Material Measurement Laboratory (MML)\n",
    "* Physical Measurement Laboratory (PML)\n",
    "\n",
    "This makes it an easy target in topic modeling.\n",
    "\n",
    "You can use also this guide to scrape other data from a webpage: http://docs.python-guide.org/en/latest/scenarios/scrape/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clustering NIST headlines and description"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import the necessary modules for the workshop. \n",
    "* [lxml](http://lxml.de/) is a package for processing XML and HTML\n",
    "    - If trouble installing on OSX, try running 'xcode-select --install'\n",
    "* [requests](http://docs.python-requests.org/en/master/) is a package for processing HTTP requests\n",
    "* [future](https://docs.python.org/2/library/__future__.html) to make a print function\n",
    "* [scikit-learn](http://scikit-learn.org/stable/index.html) is a package with broad tool sets for machine learning\n",
    "    - [TfidfVectorizer](http://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html) to vectorize raw documents into a TF-IDF matrix\n",
    "    - [KMeans](http://scikit-learn.org/stable/modules/generated/sklearn.cluster.KMeans.html#sklearn.cluster.KMeans)\n",
    "    - [MiniBatchKMeans](http://scikit-learn.org/stable/modules/generated/sklearn.cluster.KMeans.html#sklearn.cluster.KMeans)\n",
    "* [time](https://docs.python.org/2/library/time.html) to time our clustering\n",
    "* [wordcloud](https://github.com/amueller/word_cloud) to generatea visualization our data\n",
    "* [matplotlib](http://matplotlib.org/) to show the resulting image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from lxml import html\n",
    "import requests\n",
    "from __future__ import print_function\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.cluster import KMeans, MiniBatchKMeans\n",
    "from time import time\n",
    "from wordcloud import WordCloud, ImageColorGenerator, STOPWORDS\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building the list of headlines and descriptions\n",
    "\n",
    "We request NIST news based on the following URL, 'http://www.nist.gov/allnews.cfm?s=01-01-2014&e=12-31-2014'. For this workshop, we look at only 2014 news articles posted on the NIST website. \n",
    "\n",
    "We then pass that retrieved content to our HTML parser and search for a specific div class, \"select_portal_module_wrapper\" which is assigned to every headline and every description. The difference being that headlines receive a strong tag and descriptions receive a p tag.\n",
    "\n",
    "We then merge both the headline and description into one entry in the list because we don't need to differentiate between title and description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieving data from NIST\n",
      "Last item in list retrieved: A New NIST Online Database: The NIST Polycyclic Aromatic Hydrocarbon Structure Index Recently, a new website containing a wealth of information on polycyclic aromatic hydrocarbons (PAHs) was made publicly available by NIST. PAHs are compounds that are produced during the … \n"
     ]
    }
   ],
   "source": [
    "print(\"Retrieving data from NIST\")\n",
    "\n",
    "#retrieve the data from the web page\n",
    "page = requests.get('http://www.nist.gov/allnews.cfm?s=01-01-2014&e=12-31-2014') \n",
    "#use html module to parse it out and store in tree\n",
    "tree = html.fromstring(page.content)\n",
    "\n",
    "#create list of news headlines and descriptions. \n",
    "#This required obtaining the XPath of the elements by examining the web page.\n",
    "list_of_headlines = tree.xpath('//div[@class=\"select_portal_module_wrapper\"]/a/strong/text()')\n",
    "list_of_descriptions = tree.xpath('//div[@class=\"select_portal_module_wrapper\"]/p/text()')\n",
    "#combine each headline and description into one value in a list\n",
    "news=[]\n",
    "for each_headline in list_of_headlines:\n",
    "\tfor each_description in list_of_descriptions:\n",
    "\t\tnews.append(each_headline+each_description)\n",
    "\n",
    "print(\"Last item in list retrieved: %s\" % news[-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visually explore the NIST News"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we classify our NIST news dataset, we can visually explore the data that we pulled."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "stopwords = STOPWORDS.copy()\n",
    "stopwords.add('nist')\n",
    "stopwords.add('national')\n",
    "stopwords.add('institute')\n",
    "stopwords.add('standard')\n",
    "stopwords.add('standards')\n",
    "stopwords.add('technology')\n",
    "stopwords.add('new')\n",
    "wordcloud = WordCloud(background_color='#2c3e50',\n",
    "                      width=1280, \n",
    "                      height=800, \n",
    "                      scale=1, \n",
    "                      stopwords=stopwords).generate(''.join(news))\n",
    "plt.figure()\n",
    "plt.imshow(wordcloud)\n",
    "plt.axis(\"off\")\n",
    "plt.savefig('word_cloud.png', dpi=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![wordcloud](word_cloud.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert collection of documents to TF-IDF matrix\n",
    "\n",
    "We now call a TF-IDF vectorizer to create a sparse matrix with term frequency-inverse document frequency weights. We constrain vectorizer by:\n",
    "* the maximum document frequency to half the total documents,\n",
    "* the minimum document frequency to two documents,\n",
    "* and toss out common english stop words.\n",
    "\n",
    "We also time the whole thing to see how long it takes to vectorize it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting features from the training dataset using a sparse vectorizer\n",
      "done in 4.046627s\n",
      "n_samples: 110224, n_features: 12197\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Extracting features from the training dataset using a sparse vectorizer\")\n",
    "t0 = time()\n",
    "#create a sparse word occurrence frequency matrix of the most frequent words\n",
    "vectorizer = TfidfVectorizer(input=news, max_df=0.5, min_df=2, stop_words='english')\n",
    "X = vectorizer.fit_transform(news) \n",
    "\n",
    "print(\"done in %fs\" % (time() - t0))\n",
    "print(\"n_samples: %d, n_features: %d\" % X.shape)\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's do some clustering\n",
    "\n",
    "We cheat and set the number of clusters to 15 since we know there are 15 subject areas in NIST. We call the KMeans classifier from sklearn and set an upper bound to the number of iterations for fitting the data to the classifier. We again time the process to see how long it takes to fit. Finally we list out each centroid and the top 10 terms associated with each centroid."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clustering sparse data with KMeans(copy_x=True, init='k-means++', max_iter=100, n_clusters=15, n_init=10,\n",
      "    n_jobs=1, precompute_distances='auto', random_state=None, tol=0.0001,\n",
      "    verbose=0)\n",
      "done in 85.226s\n",
      "\n",
      "Top terms per cluster:\n",
      "Cluster 0: chip initiative image pure 2014 ready gas time measurements world\n",
      "Cluster 1: scientists produced crystal case using ptir photothermal lateral pahs resonance\n",
      "Cluster 2: research technology committee institute national standards visiting advanced agency primary\n",
      "Cluster 3: cnst nanoscale center test developed new used technology laser science\n",
      "Cluster 4: baldrige excellence award performance program malcolm quality organizations 2014 penny\n",
      "Cluster 5: department commerce released technology standards national institute report president year\n",
      "Cluster 6: forensic science committees osac organization area scientific members new standards\n",
      "Cluster 7: 00 dna wednesday sequencer et participate analysts webinar invited free\n",
      "Cluster 8: award house researchers recipients honored awards flemming career conditions extremely\n",
      "Cluster 9: dimensional pml metrology semiconductor division ultra colleagues researchers electron images\n",
      "Cluster 10: demonstrated atomic technology national standards new based institute clock way\n",
      "Cluster 11: extension hollings partnership manufacturing mep new standards institute technology national\n",
      "Cluster 12: work cloud computing rpki electron energy terrorist strategic methods roadmap\n",
      "Cluster 13: framework ago critical devoted workshops infrastructure developing community disaster resilience\n",
      "Cluster 14: standards technology institute national information new systems public 2014 draft\n"
     ]
    }
   ],
   "source": [
    "k = 15\n",
    "km = KMeans(n_clusters=k, init='k-means++', max_iter=100)\n",
    "\n",
    "print(\"Clustering sparse data with %s\" % km)\n",
    "t0 = time()\n",
    "km.fit(X) \t\t\t\t\t\t\t\t#what's happening here??\n",
    "print(\"done in %0.3fs\" % (time() - t0))\n",
    "print()\n",
    "\n",
    "print(\"Top terms per cluster:\")\n",
    "order_centroids = km.cluster_centers_.argsort()[:, ::-1]\n",
    "\n",
    "terms = vectorizer.get_feature_names()\n",
    "for i in range(k):\n",
    "    print(\"Cluster %d:\" % i, end='')\n",
    "    for ind in order_centroids[i, :10]:\n",
    "        print(' %s' % terms[ind], end='')\n",
    "    print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
